#!/usr/bin/env python

"""
step5_compute_gradient.py

Computes the AVO Intercept (R0) and Gradient (G) for each
synthetic reflectivity curve generated by mc_draw.py.

This script implements Step 5 of the rock physics workflow:
"Step 5: Compute intercept and and gradient values for each reflectivity curve"

Usage:
    python step5_compute_gradient.py

Inputs:
    - avo_data.pkl: A dictionary where keys are facies names (e.g., 'FaciesIIaOil')
                    and values are dicts {'angles': array, 'Rpp': 2D array}.
                    (Generated by mc_draw.py)

Outputs:
    - intercept_gradient_data.pkl: A dictionary containing the computed
                                   Intercept and Gradient arrays for each facies.
    - intercept_gradient_subplots.png: A 3x3 diagnostic plot of the
                                       (Intercept, Gradient) clouds for
                                       each facies (like lecture page 27).
    - intercept_gradient_combined.png: A single diagnostic plot combining
                                       all facies (like lecture page 28).
"""

import numpy as np
import matplotlib.pyplot as plt
import pickle

# --- Facies Definitions (to match mc_draw.py and lecture) ---

# Define the 9 facies cases TO MATCH THE KEYS IN mc_draw.py
FACIES_NAMES = [
    'FaciesIIaOil', 'FaciesIIbOil', 'FaciesIIcOil',
    'FaciesIIa',     'FaciesIIb',     'FaciesIIc',
    'FaciesIII',     'FaciesIV',      'FaciesV'
]

# Define the colors for each facies (matching lecture slides)
# Using the same hex codes for consistency
FACIES_COLORS = {
    'FaciesIIaOil': '#8B0000', # dark red
    'FaciesIIbOil': '#FFA500', # orange
    'FaciesIIcOil': '#FF00FF', # magenta
    'FaciesIIa':     '#8B0000', # dark red
    'FaciesIIb':     '#FFA500', # orange
    'FaciesIIc':     '#FF00FF', # magenta
    'FaciesIII':     '#008000', # green
    'FaciesIV':      '#00FFFF', # cyan
    'FaciesV':       '#0000FF'  # blue
}

# --- Main Functions ---

def load_data(filename="avo_data.pkl"):
    """
    Loads the AVO data (theta and reflectivity curves) from a pickle file.
    This version is compatible with the output of mc_draw.py.
    """
    print(f"Loading synthetic AVO data from {filename}...")
    try:
        with open(filename, 'rb') as f:
            data = pickle.load(f)
        
        # Validate data
        if not isinstance(data, dict) or 'FaciesIV' not in data:
            raise ValueError("File is not a valid dictionary or is missing expected facies keys.")
        
        print("Load successful.")
        return data
        
    except FileNotFoundError:
        print(f"Error: Input file '{filename}' not found.")
        print("Please run 'mc_draw.py' to generate this file.")
        exit(1)
    except Exception as e:
        print(f"Error loading {filename}: {e}")
        exit(1)

def compute_gradient_intercept(avo_data):
    """
    Calculates Intercept (R0) and Gradient (G) for all reflectivity curves
    using the Shuey 2-term approximation: R(theta) = R0 + G*sin^2(theta).
    
    This version reads the data structure from mc_draw.py.
    """
    print("Computing Intercept (R0) and Gradient (G) for all facies...")
    
    intercept_gradient_data = {}
    theta = None
    x_data = None # This will be sin^2(theta)

    # Loop over the actual facies names from the loaded file
    for facies_name, facies_data in avo_data.items():
        
        if 'angles' not in facies_data or 'Rpp' not in facies_data:
            print(f"Warning: Skipping {facies_name}, missing 'angles' or 'Rpp'.")
            continue
            
        # On the first valid facies, get the angle array
        if theta is None:
            theta = facies_data['angles']
            # Pre-calculate the x-axis for the linear regression: sin^2(theta)
            # Convert theta from degrees to radians for numpy's sin function
            theta_rad = np.deg2rad(theta)
            x_data = np.sin(theta_rad)**2
        
        # Ensure angle array is consistent
        if x_data is None or len(facies_data['angles']) != len(theta):
            print(f"Warning: Skipping {facies_name}, angle array mismatch.")
            continue
            
        curves = facies_data['Rpp'] # Shape: (n_simulations, n_angles)
        
        intercepts = []
        gradients = []

        # Loop through each individual reflectivity curve (each simulation)
        for curve in curves:
            # R(theta) = R0 + G*sin^2(theta)
            # This is a linear equation: y = c + m*x
            # y = curve
            # x = x_data (sin^2(theta))
            # m = G (Gradient)
            # c = R0 (Intercept)
            
            # np.polyfit(x, y, 1) returns [m, c] which is [G, R0]
            G, R0 = np.polyfit(x_data, curve, 1)
            
            intercepts.append(R0)
            gradients.append(G)
        
        # Store results for this facies
        intercept_gradient_data[facies_name] = {
            'intercept': np.array(intercepts),
            'gradient': np.array(gradients)
        }

    if theta is None:
        print("Error: No valid facies data was found to process.")
        return None

    print("Computation complete.")
    return intercept_gradient_data

def save_data(data, filename="intercept_gradient_data.pkl"):
    """
    Saves the computed Intercept/Gradient data to a pickle file.
    """
    print(f"Saving Intercept/Gradient data to {filename}...")
    with open(filename, 'wb') as f:
        pickle.dump(data, f)
    print("Save successful.")

def plot_data(ig_data):
    """
    Generates two plots:
    1. A 3x3 grid of scatter plots (like lecture page 27).
    2. A combined scatter plot (like lecture page 28).
    
    This version uses the facies names from FACIES_NAMES for ordering and coloring.
    """
    print("Generating diagnostic plots...")

    # --- Plot 1: 3x3 Subplots (Page 27) ---
    fig, axes = plt.subplots(3, 3, figsize=(15, 15))
    axes = axes.ravel() # Flatten the 3x3 grid to a 1D array for easy looping

    # Use the consistent FACIES_NAMES list for plotting order
    for i, facies_name in enumerate(FACIES_NAMES):
        ax = axes[i]
        
        if facies_name not in ig_data:
            print(f"Warning: No Intercept/Gradient data found for {facies_name}.")
            ax.set_title(facies_name, fontsize=14)
            ax.text(0.5, 0.5, "No Data", ha='center', va='center', transform=ax.transAxes)
            continue
            
        data = ig_data[facies_name]
        color = FACIES_COLORS.get(facies_name, 'gray') # Get facies color
        
        intercept = data['intercept']
        gradient = data['gradient']
        
        # Plot the point cloud
        ax.scatter(intercept, gradient, c=color, alpha=0.7, s=10)
        
        # Plot the mean value (as in lecture)
        mean_intercept = np.mean(intercept)
        mean_gradient = np.mean(gradient)
        ax.scatter(mean_intercept, mean_gradient, c='black', s=50, 
                   edgecolor='white', zorder=5)

        # Formatting
        ax.set_title(facies_name, fontsize=14)
        ax.set_xlabel('Intercept', fontsize=12)
        ax.set_ylabel('Gradient', fontsize=12)
        ax.set_xlim(-0.25, 0.25) # Adjusted limits to better center data
        ax.set_ylim(-0.4, 0.3)  # Adjusted limits to better center data
        ax.grid(True, linestyle=':', alpha=0.7)

    # Hide any unused subplots (should not happen if all 9 facies are present)
    for j in range(i + 1, len(axes)):
        axes[j].axis('off')

    plt.suptitle("Step 5: Intercept vs. Gradient Clouds (by Facies)", fontsize=18)
    plt.tight_layout(rect=[0, 0.03, 1, 0.96])
    plot_filename_1 = 'intercept_gradient_subplots.png'
    plt.savefig(plot_filename_1)
    print(f"Saved subplot plot to {plot_filename_1}")
    plt.close(fig)

    # --- Plot 2: Combined Plot (Page 28) ---
    fig, ax = plt.subplots(figsize=(10, 8))

    # Use FACIES_NAMES to control plotting order if needed, but iterating ig_data is fine
    for facies_name, data in ig_data.items():
        
        color = FACIES_COLORS.get(facies_name, 'gray') # Get color from our consistent dict
        
        intercept = data['intercept']
        gradient = data['gradient']
        
        # Plot the point cloud
        ax.scatter(intercept, gradient, c=color, alpha=0.5, s=10, 
                   label=facies_name)
        
        # Plot the mean value
        mean_intercept = np.mean(intercept)
        mean_gradient = np.mean(gradient)
        ax.scatter(mean_intercept, mean_gradient, c='black', s=50, 
                   edgecolor='white', zorder=5)

    # Formatting
    ax.set_title('All Facies - Intercept vs Gradient', fontsize=16)
    ax.set_xlabel('Intercept', fontsize=14)
    ax.set_ylabel('Gradient', fontsize=14)
    ax.set_xlim(-0.25, 0.25)
    ax.set_ylim(-0.4, 0.3)
    ax.grid(True, linestyle=':', alpha=0.7)
    # Note: No legend, to match the style of lecture page 28
    
    plot_filename_2 = 'intercept_gradient_combined.png'
    plt.savefig(plot_filename_2)
    print(f"Saved combined plot to {plot_filename_2}")
    plt.close(fig)

# --- Main execution ---

if __name__ == "__main__":
    # 1. Load data from Step 4 (mc_draw.py)
    avo_data = load_data("avo_data.pkl")
    
    if avo_data:
        # 2. Compute Intercept and Gradient
        intercept_gradient_data = compute_gradient_intercept(avo_data)
        
        if intercept_gradient_data:
            # 3. Save data for Step 6
            save_data(intercept_gradient_data, "intercept_gradient_data.pkl")
            
            # 4. Create diagnostic plots
            plot_data(intercept_gradient_data)
            
            print("\nStep 5 complete.")
        else:
            print("\nStep 5 failed: Could not compute Intercept/Gradient data.")
    else:
        print("\nStep 5 failed: Could not load AVO data.")